# Machine Learning

The following problem cannot be solved with machine learning. RAG is fundamentally about generating fluent, contextualized natural language responses, and traditional ML models aren't designed to generate language, much less with the flexibility, reasoning, and adaptability that RAG demands. Machine Learning models in a nutshell are built to: Classify things, Score things, and Rank things. Generating a coherent sequence of words is not part of what they are meant to do. Even though with effective training and implementation, it is possible to have them classify the next best word, the use case just does not fit. Just because something can be done does not mean that it should be done. Traditional ML models are not equipped to do multi-hop reasoning, context-sensitive summarization, or handle vague or underspecified prompts. LLMs, by contrast, have been pretrained to do exactly that across millions of examples.

There is also no guarantee in answer grounding - even in a RAG setup, LLMs often pull from their training distribution instead of the retrieval output, especially if the query resembles something it "thinks" it knows. For a traditional ML approach, it is almost impossible for the model to pull information from the context we retrieve and give to it. Trying to plug in a non-generative ML model into the "generation" slot is like putting a toaster where the printer should go. You might get heat, but not a document.

Some concepts and ideas were taken from ChatGPT with the prompt - "Why can you not build a RAG framework with an ML model placed in the pipeline instead of a Large Language Model?" ~ on April 7th 2025 at 7:41 PM.